{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efce0fe1-3d55-439d-8762-a78cd5409c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:32:19.406827Z",
     "iopub.status.busy": "2025-03-03T15:32:19.405814Z",
     "iopub.status.idle": "2025-03-03T15:32:19.416708Z",
     "shell.execute_reply": "2025-03-03T15:32:19.414712Z",
     "shell.execute_reply.started": "2025-03-03T15:32:19.406827Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import talib\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9cc45b-645a-4c7e-9d05-fa5f199ed384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:32:19.420706Z",
     "iopub.status.busy": "2025-03-03T15:32:19.419709Z",
     "iopub.status.idle": "2025-03-03T15:32:19.451670Z",
     "shell.execute_reply": "2025-03-03T15:32:19.450649Z",
     "shell.execute_reply.started": "2025-03-03T15:32:19.420706Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import  DataSource\n",
    "import Utils\n",
    "zz500 = DataSource.get_zz500_codes() # 我看中证500的数据\n",
    "# 我这里查看第一个股票的吧\n",
    "N = 60 # 多少日的数据\n",
    "# 我这里仅仅是记录如下的列的涨跌幅度\n",
    "rate_columns = ['open', 'high', 'low', 'close']\n",
    "close_index = rate_columns.index('close')\n",
    "input_size = len(rate_columns)\n",
    "seq_len = N    # 多少个时间序列的股票\n",
    "output_size = 1 # 我只是输出一个今天的收盘价相比较昨日的涨跌比率\n",
    "num_layers = 2 # 多少个gru合并\n",
    "hidden_size = 128 # 隐藏层的宽度\n",
    "batch_size = 64 # 一个批次有多少个数据\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f46d189-41bf-48b3-aa41-57baf569be75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:32:19.455667Z",
     "iopub.status.busy": "2025-03-03T15:32:19.454670Z",
     "iopub.status.idle": "2025-03-03T15:32:19.485533Z",
     "shell.execute_reply": "2025-03-03T15:32:19.483517Z",
     "shell.execute_reply.started": "2025-03-03T15:32:19.455667Z"
    }
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(row):\n",
    "    # 最大最小值归一化\n",
    "    return (row - row.min())/(row.max() - row.min())\n",
    "    \n",
    "def get_loader(code_name, N=60, rate_columns=['open', 'high', 'low', 'close'], batch_size=16, train_rate=0.9):\n",
    "    dt = DataSource.get_data(code_name)\n",
    "    dt_list = []\n",
    "    for j in range(N):\n",
    "        # N+1表示要多一天，比如前面30天，我要看看第31天的收盘价相对于第一天的收盘价是什么比例\n",
    "        for i in rate_columns:\n",
    "            dt_tmp = pd.DataFrame({f'{i}_{j}':dt[f'{i}'].shift(-j)})\n",
    "            dt_list.append(dt_tmp)\n",
    "    # 拼接\n",
    "    dt2 = pd.concat(dt_list, axis=1)\n",
    "    # 然后这里要按照行进行归一化\n",
    "    row_means = dt2.mean(axis=1) # 按行取均值\n",
    "    row_std = dt2.std(axis=1)    # 按行取标准差\n",
    "    # normalize each row with its mean and standard deviation\n",
    "    dt3 = dt2.sub(row_means, axis=0).div(row_std, axis=0)\n",
    "    # dt3 = dt2.apply(min_max_normalization, axis=1)\n",
    "    # x\n",
    "    x_price = dt3.to_numpy()\n",
    "    x_price = x_price[:-(N+1)]\n",
    "    # 更改维度\n",
    "    x_shape_old = x_price.shape\n",
    "    x_shape_new_1 = x_shape_old[0]\n",
    "    x_shape_new_3 = len(rate_columns)\n",
    "    x_shape_new_2 = int(x_shape_old[1] / x_shape_new_3)\n",
    "    x_price = x_price.reshape((x_shape_new_1, x_shape_new_2, x_shape_new_3))\n",
    "    # y，是涨跌幅度\n",
    "    dt['close2'] = dt['close'].shift(-N)\n",
    "    dt['close3'] = dt['close'].shift(-(N+1))\n",
    "    dt['close4'] = (dt['close3']-dt['close2'])/dt['close2']\n",
    "    y_close = dt['close4'].to_numpy()[:-(N+1)]\n",
    "    # 然后是批次的整数倍\n",
    "    _x_y_len = int(x_price.shape[0]/batch_size) * batch_size\n",
    "    #\n",
    "    x_price = x_price[-_x_y_len:]\n",
    "    y_close = y_close[-_x_y_len:]\n",
    "    x_price = x_price.reshape(\n",
    "        x_price.shape[0]//batch_size,\n",
    "        batch_size,\n",
    "        x_price.shape[1],\n",
    "        x_price.shape[2])\n",
    "    y_close = y_close.reshape(y_close.shape[0]//batch_size, batch_size, 1)\n",
    "    # 做成加载器\n",
    "    dataset = Data.TensorDataset(\n",
    "        torch.FloatTensor(x_price),\n",
    "        torch.FloatTensor(y_close))\n",
    "    train_loader, test_loader = Data.random_split(\n",
    "        dataset,\n",
    "        lengths=[\n",
    "            int(train_rate*len(dataset)),\n",
    "            len(dataset)-int(train_rate*len(dataset))],\n",
    "        generator=torch.Generator().manual_seed(0))\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73100b4d-4c8a-433a-8d15-dd4809d22058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:32:19.491551Z",
     "iopub.status.busy": "2025-03-03T15:32:19.490543Z",
     "iopub.status.idle": "2025-03-03T15:32:19.513298Z",
     "shell.execute_reply": "2025-03-03T15:32:19.510307Z",
     "shell.execute_reply.started": "2025-03-03T15:32:19.491551Z"
    }
   },
   "outputs": [],
   "source": [
    "# 一个gru网络\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True) \n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)  # gru层\n",
    "        out = self.fc(out[:, -1, :])  # 全连接层\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944d6d0d-3aa2-4f06-bbd2-bc5b8a1f7f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:32:19.537300Z",
     "iopub.status.busy": "2025-03-03T15:32:19.535302Z",
     "iopub.status.idle": "2025-03-03T15:34:19.735806Z",
     "shell.execute_reply": "2025-03-03T15:34:19.730789Z",
     "shell.execute_reply.started": "2025-03-03T15:32:19.536301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, avg labels: 0.01473 avg loss:0.01575, max loss: 0.04490, min loss : 0.00658\n",
      "2, avg labels: 0.01473 avg loss:0.01487, max loss: 0.04471, min loss : 0.00642\n",
      "3, avg labels: 0.01473 avg loss:0.01483, max loss: 0.04474, min loss : 0.00639\n",
      "4, avg labels: 0.01473 avg loss:0.01482, max loss: 0.04471, min loss : 0.00641\n",
      "5, avg labels: 0.01473 avg loss:0.01482, max loss: 0.04470, min loss : 0.00639\n",
      "6, avg labels: 0.01473 avg loss:0.01484, max loss: 0.04471, min loss : 0.00641\n",
      "7, avg labels: 0.01473 avg loss:0.01483, max loss: 0.04472, min loss : 0.00642\n",
      "8, avg labels: 0.01473 avg loss:0.01483, max loss: 0.04472, min loss : 0.00640\n",
      "9, avg labels: 0.01473 avg loss:0.01483, max loss: 0.04472, min loss : 0.00641\n",
      "10, avg labels: 0.01473 avg loss:0.01480, max loss: 0.04472, min loss : 0.00643\n",
      "11, avg labels: 0.01473 avg loss:0.01483, max loss: 0.04471, min loss : 0.00645\n",
      "12, avg labels: 0.01473 avg loss:0.01480, max loss: 0.04468, min loss : 0.00642\n",
      "13, avg labels: 0.01473 avg loss:0.01482, max loss: 0.04469, min loss : 0.00642\n",
      "14, avg labels: 0.01473 avg loss:0.01479, max loss: 0.04466, min loss : 0.00645\n",
      "15, avg labels: 0.01473 avg loss:0.01479, max loss: 0.04470, min loss : 0.00643\n",
      "16, avg labels: 0.01473 avg loss:0.01478, max loss: 0.04467, min loss : 0.00642\n",
      "17, avg labels: 0.01473 avg loss:0.01477, max loss: 0.04466, min loss : 0.00641\n",
      "18, avg labels: 0.01473 avg loss:0.01477, max loss: 0.04468, min loss : 0.00639\n",
      "19, avg labels: 0.01473 avg loss:0.01478, max loss: 0.04468, min loss : 0.00642\n",
      "20, avg labels: 0.01473 avg loss:0.01476, max loss: 0.04470, min loss : 0.00638\n",
      "21, avg labels: 0.01473 avg loss:0.01477, max loss: 0.04467, min loss : 0.00641\n",
      "22, avg labels: 0.01473 avg loss:0.01476, max loss: 0.04470, min loss : 0.00639\n",
      "23, avg labels: 0.01473 avg loss:0.01475, max loss: 0.04465, min loss : 0.00640\n",
      "24, avg labels: 0.01473 avg loss:0.01475, max loss: 0.04466, min loss : 0.00639\n",
      "25, avg labels: 0.01473 avg loss:0.01473, max loss: 0.04465, min loss : 0.00641\n",
      "26, avg labels: 0.01473 avg loss:0.01475, max loss: 0.04466, min loss : 0.00643\n",
      "27, avg labels: 0.01473 avg loss:0.01473, max loss: 0.04467, min loss : 0.00640\n",
      "28, avg labels: 0.01473 avg loss:0.01473, max loss: 0.04464, min loss : 0.00642\n",
      "29, avg labels: 0.01473 avg loss:0.01474, max loss: 0.04466, min loss : 0.00643\n",
      "30, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04467, min loss : 0.00644\n",
      "31, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04468, min loss : 0.00641\n",
      "32, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04468, min loss : 0.00648\n",
      "33, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04466, min loss : 0.00641\n",
      "34, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04467, min loss : 0.00645\n",
      "35, avg labels: 0.01473 avg loss:0.01470, max loss: 0.04463, min loss : 0.00639\n",
      "36, avg labels: 0.01473 avg loss:0.01469, max loss: 0.04465, min loss : 0.00637\n",
      "37, avg labels: 0.01473 avg loss:0.01470, max loss: 0.04460, min loss : 0.00638\n",
      "38, avg labels: 0.01473 avg loss:0.01471, max loss: 0.04465, min loss : 0.00628\n",
      "39, avg labels: 0.01473 avg loss:0.01469, max loss: 0.04464, min loss : 0.00627\n",
      "40, avg labels: 0.01473 avg loss:0.01468, max loss: 0.04465, min loss : 0.00635\n",
      "41, avg labels: 0.01473 avg loss:0.01468, max loss: 0.04464, min loss : 0.00633\n",
      "42, avg labels: 0.01473 avg loss:0.01467, max loss: 0.04457, min loss : 0.00632\n",
      "43, avg labels: 0.01473 avg loss:0.01466, max loss: 0.04464, min loss : 0.00624\n",
      "44, avg labels: 0.01473 avg loss:0.01466, max loss: 0.04457, min loss : 0.00624\n",
      "45, avg labels: 0.01473 avg loss:0.01469, max loss: 0.04449, min loss : 0.00625\n",
      "46, avg labels: 0.01473 avg loss:0.01466, max loss: 0.04461, min loss : 0.00617\n",
      "47, avg labels: 0.01473 avg loss:0.01466, max loss: 0.04453, min loss : 0.00617\n",
      "48, avg labels: 0.01473 avg loss:0.01466, max loss: 0.04461, min loss : 0.00619\n",
      "49, avg labels: 0.01473 avg loss:0.01467, max loss: 0.04457, min loss : 0.00619\n",
      "50, avg labels: 0.01473 avg loss:0.01467, max loss: 0.04458, min loss : 0.00614\n",
      "51, avg labels: 0.01473 avg loss:0.01463, max loss: 0.04451, min loss : 0.00612\n",
      "52, avg labels: 0.01473 avg loss:0.01463, max loss: 0.04449, min loss : 0.00615\n",
      "53, avg labels: 0.01473 avg loss:0.01462, max loss: 0.04449, min loss : 0.00613\n",
      "54, avg labels: 0.01473 avg loss:0.01463, max loss: 0.04450, min loss : 0.00614\n",
      "55, avg labels: 0.01473 avg loss:0.01462, max loss: 0.04450, min loss : 0.00613\n",
      "56, avg labels: 0.01473 avg loss:0.01461, max loss: 0.04450, min loss : 0.00612\n",
      "57, avg labels: 0.01473 avg loss:0.01461, max loss: 0.04452, min loss : 0.00613\n",
      "58, avg labels: 0.01473 avg loss:0.01461, max loss: 0.04450, min loss : 0.00618\n",
      "59, avg labels: 0.01473 avg loss:0.01464, max loss: 0.04455, min loss : 0.00616\n",
      "60, avg labels: 0.01473 avg loss:0.01462, max loss: 0.04454, min loss : 0.00609\n",
      "61, avg labels: 0.01473 avg loss:0.01461, max loss: 0.04451, min loss : 0.00614\n",
      "62, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04449, min loss : 0.00614\n",
      "63, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04446, min loss : 0.00613\n",
      "64, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04442, min loss : 0.00616\n",
      "65, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04441, min loss : 0.00612\n",
      "66, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04442, min loss : 0.00610\n",
      "67, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04445, min loss : 0.00608\n",
      "68, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04448, min loss : 0.00606\n",
      "69, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04451, min loss : 0.00607\n",
      "70, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04446, min loss : 0.00609\n",
      "71, avg labels: 0.01473 avg loss:0.01460, max loss: 0.04448, min loss : 0.00609\n",
      "72, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04449, min loss : 0.00605\n",
      "73, avg labels: 0.01473 avg loss:0.01458, max loss: 0.04450, min loss : 0.00607\n",
      "74, avg labels: 0.01473 avg loss:0.01456, max loss: 0.04445, min loss : 0.00608\n",
      "75, avg labels: 0.01473 avg loss:0.01456, max loss: 0.04444, min loss : 0.00610\n",
      "76, avg labels: 0.01473 avg loss:0.01455, max loss: 0.04443, min loss : 0.00611\n",
      "77, avg labels: 0.01473 avg loss:0.01456, max loss: 0.04446, min loss : 0.00610\n",
      "78, avg labels: 0.01473 avg loss:0.01456, max loss: 0.04446, min loss : 0.00608\n",
      "79, avg labels: 0.01473 avg loss:0.01454, max loss: 0.04444, min loss : 0.00609\n",
      "80, avg labels: 0.01473 avg loss:0.01453, max loss: 0.04444, min loss : 0.00608\n",
      "81, avg labels: 0.01473 avg loss:0.01449, max loss: 0.04436, min loss : 0.00607\n",
      "82, avg labels: 0.01473 avg loss:0.01448, max loss: 0.04438, min loss : 0.00602\n",
      "83, avg labels: 0.01473 avg loss:0.01447, max loss: 0.04432, min loss : 0.00603\n",
      "84, avg labels: 0.01473 avg loss:0.01446, max loss: 0.04437, min loss : 0.00600\n",
      "85, avg labels: 0.01473 avg loss:0.01446, max loss: 0.04435, min loss : 0.00601\n",
      "86, avg labels: 0.01473 avg loss:0.01446, max loss: 0.04435, min loss : 0.00601\n",
      "87, avg labels: 0.01473 avg loss:0.01445, max loss: 0.04438, min loss : 0.00599\n",
      "88, avg labels: 0.01473 avg loss:0.01445, max loss: 0.04436, min loss : 0.00600\n",
      "89, avg labels: 0.01473 avg loss:0.01446, max loss: 0.04440, min loss : 0.00602\n",
      "90, avg labels: 0.01473 avg loss:0.01445, max loss: 0.04437, min loss : 0.00601\n",
      "91, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04437, min loss : 0.00601\n",
      "92, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04436, min loss : 0.00602\n",
      "93, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04439, min loss : 0.00601\n",
      "94, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04439, min loss : 0.00599\n",
      "95, avg labels: 0.01473 avg loss:0.01443, max loss: 0.04439, min loss : 0.00601\n",
      "96, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04438, min loss : 0.00600\n",
      "97, avg labels: 0.01473 avg loss:0.01444, max loss: 0.04439, min loss : 0.00602\n",
      "98, avg labels: 0.01473 avg loss:0.01443, max loss: 0.04438, min loss : 0.00602\n",
      "99, avg labels: 0.01473 avg loss:0.01443, max loss: 0.04439, min loss : 0.00600\n",
      "100, avg labels: 0.01473 avg loss:0.01443, max loss: 0.04439, min loss : 0.00600\n",
      "实际值: tensor([[-0.0143],\n",
      "        [ 0.0217],\n",
      "        [-0.0020],\n",
      "        [-0.0041],\n",
      "        [ 0.0031],\n",
      "        [-0.0071],\n",
      "        [ 0.0398],\n",
      "        [ 0.0000],\n",
      "        [-0.0029],\n",
      "        [-0.0167],\n",
      "        [-0.0050],\n",
      "        [ 0.0242],\n",
      "        [-0.0020],\n",
      "        [-0.0177],\n",
      "        [-0.0211],\n",
      "        [-0.0072],\n",
      "        [ 0.0000],\n",
      "        [-0.0175],\n",
      "        [ 0.0168],\n",
      "        [-0.0083],\n",
      "        [-0.0208],\n",
      "        [ 0.0160],\n",
      "        [ 0.0220],\n",
      "        [ 0.0225],\n",
      "        [ 0.0070],\n",
      "        [ 0.0090],\n",
      "        [-0.0197],\n",
      "        [ 0.0402],\n",
      "        [ 0.0106],\n",
      "        [ 0.0010],\n",
      "        [-0.0220],\n",
      "        [-0.0117],\n",
      "        [-0.0010],\n",
      "        [ 0.0297],\n",
      "        [-0.0125],\n",
      "        [ 0.0166],\n",
      "        [-0.0144],\n",
      "        [ 0.0010],\n",
      "        [ 0.0437],\n",
      "        [-0.0130],\n",
      "        [ 0.0207],\n",
      "        [ 0.0055],\n",
      "        [ 0.0018],\n",
      "        [ 0.0202],\n",
      "        [-0.0171],\n",
      "        [-0.0174],\n",
      "        [-0.0102],\n",
      "        [-0.0855],\n",
      "        [ 0.0144],\n",
      "        [-0.0446],\n",
      "        [-0.0170],\n",
      "        [ 0.0097],\n",
      "        [ 0.0000],\n",
      "        [-0.0150],\n",
      "        [-0.0249],\n",
      "        [ 0.0122],\n",
      "        [ 0.0154],\n",
      "        [-0.0152],\n",
      "        [ 0.0066],\n",
      "        [-0.0240],\n",
      "        [-0.0011],\n",
      "        [ 0.0056],\n",
      "        [-0.0045],\n",
      "        [-0.0045]], device='cuda:0')\n",
      "预测值: tensor([[ 1.4790e-04],\n",
      "        [ 1.6823e-03],\n",
      "        [ 4.0592e-03],\n",
      "        [ 3.1377e-03],\n",
      "        [ 1.2816e-03],\n",
      "        [-1.1026e-03],\n",
      "        [-7.1415e-04],\n",
      "        [-2.7756e-04],\n",
      "        [-6.2266e-03],\n",
      "        [-7.2218e-03],\n",
      "        [-6.6104e-03],\n",
      "        [ 1.1953e-03],\n",
      "        [ 1.4521e-03],\n",
      "        [ 1.0381e-03],\n",
      "        [ 1.5348e-03],\n",
      "        [ 1.5514e-03],\n",
      "        [-6.4094e-04],\n",
      "        [-1.9928e-03],\n",
      "        [ 1.8878e-04],\n",
      "        [ 2.6637e-03],\n",
      "        [ 4.8391e-04],\n",
      "        [ 2.5476e-03],\n",
      "        [ 2.8387e-04],\n",
      "        [-4.2113e-04],\n",
      "        [-1.0509e-03],\n",
      "        [-7.3289e-03],\n",
      "        [-8.1380e-03],\n",
      "        [-8.0874e-03],\n",
      "        [ 5.7422e-04],\n",
      "        [ 2.7609e-03],\n",
      "        [ 1.5406e-03],\n",
      "        [-8.7384e-05],\n",
      "        [-5.9200e-04],\n",
      "        [-7.2965e-05],\n",
      "        [ 7.5533e-04],\n",
      "        [-1.5261e-03],\n",
      "        [-9.8627e-04],\n",
      "        [-1.4279e-03],\n",
      "        [-6.6932e-04],\n",
      "        [-2.9450e-04],\n",
      "        [-2.7678e-03],\n",
      "        [-2.7090e-03],\n",
      "        [-4.0950e-03],\n",
      "        [-2.6665e-03],\n",
      "        [-5.8380e-04],\n",
      "        [-5.3757e-04],\n",
      "        [ 1.2762e-03],\n",
      "        [ 6.7918e-05],\n",
      "        [ 7.5282e-04],\n",
      "        [ 1.5371e-03],\n",
      "        [ 2.2747e-03],\n",
      "        [ 3.4120e-03],\n",
      "        [ 2.6324e-04],\n",
      "        [-2.7129e-03],\n",
      "        [-2.1546e-03],\n",
      "        [-1.7905e-03],\n",
      "        [-2.2935e-03],\n",
      "        [-2.4150e-03],\n",
      "        [-1.5370e-03],\n",
      "        [-1.4435e-03],\n",
      "        [-1.5654e-03],\n",
      "        [-8.6217e-04],\n",
      "        [-1.0387e-03],\n",
      "        [-3.8720e-04]], device='cuda:0')\n",
      "test : max loss : 0.019249552860856056, min loss: 0.008861616253852844, avg loss : 0.012721358332782984\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 创建窗口并初始化\n",
    "# 训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = GRUModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "criterion = torch.nn.L1Loss()  # 绝对值误差函数\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "train_loader, test_loader = get_loader(\n",
    "    zz500[0],\n",
    "    N=20,\n",
    "    batch_size=batch_size,\n",
    "    train_rate=0.9)\n",
    "Utils.do_train(100, train_loader, net, optimizer, criterion)\n",
    "# 接下来做测试\n",
    "Utils.do_test(test_loader, net, criterion)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438b292-c5d0-4c52-8e6f-71156d6ad0c7",
   "metadata": {},
   "source": [
    "可以看到预测结果倾向于0，然后就是损失函数最少的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c37e7b-491d-4252-af07-036f7fc5783d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
